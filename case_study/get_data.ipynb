{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import gzip\n",
    "import tarfile\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get TCGA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_ids(dataset_name):\n",
    "    print(f\"\\tGetting files ids for {dataset_name}\")\n",
    "    filters = {\n",
    "        \"op\": \"and\",\n",
    "        \"content\":[\n",
    "            {\n",
    "            \"op\": \"in\",\n",
    "            \"content\":{\n",
    "                \"field\": \"cases.project.project_id\",\n",
    "                \"value\": [f\"TCGA-{dataset_name}\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "            \"op\": \"in\",\n",
    "            \"content\":{\n",
    "                \"field\": \"files.data_category\",\n",
    "                \"value\": [\"Transcriptome Profiling\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "            \"op\": \"in\",\n",
    "            \"content\":{\n",
    "                \"field\": \"files.data_type\",\n",
    "                \"value\": [\"Gene Expression Quantification\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "            \"op\": \"in\",\n",
    "            \"content\":{\n",
    "                \"field\": \"files.experimental_strategy\",\n",
    "                \"value\": [\"RNA-Seq\"]\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        \"filters\": json.dumps(filters),\n",
    "        \"fields\": \"file_id\",\n",
    "        \"format\": \"JSON\",\n",
    "        \"size\": \"10000\"\n",
    "        }\n",
    "    response = requests.get(\"https://api.gdc.cancer.gov/files\", params = params)\n",
    "    files_ids = [file_entry[\"file_id\"] for file_entry in json.loads(response.content.decode(\"utf-8\"))[\"data\"][\"hits\"]]\n",
    "\n",
    "    return files_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files(dataset_name, files_ids, folder=\"\"):\n",
    "    print(f\"\\tDownloading files for {dataset_name}\")\n",
    "    params = {\"ids\": files_ids}\n",
    "    response = requests.post(\"https://api.gdc.cancer.gov/data\", data = json.dumps(params), headers = {\"Content-Type\": \"application/json\"})\n",
    "    filename = re.findall(\"filename=(.+)\", response.headers[\"Content-Disposition\"])[0]\n",
    "\n",
    "    with open(f\"{os.path.join(folder, dataset_name)}_raw_data.tar.gz\", \"wb\") as output_file:\n",
    "        output_file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_samples_info(dataset_name, files_ids):\n",
    "    print(f\"\\tDownloading samples info for {dataset_name}\")\n",
    "    filters = {\n",
    "        \"op\": \"and\",\n",
    "        \"content\":[\n",
    "            {\n",
    "            \"op\": \"in\",\n",
    "            \"content\":{\n",
    "                \"field\": \"files.file_id\",\n",
    "                \"value\": files_ids\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    fields = [\n",
    "        \"file_id\",\n",
    "        \"file_name\",\n",
    "        \"cases.case_id\",\n",
    "        \"cases.samples.portions.analytes.aliquots.submitter_id\",\n",
    "        \"cases.samples.sample_type\"\n",
    "    ]\n",
    "    params = {\n",
    "        \"filters\": filters,\n",
    "        \"fields\": \",\".join(fields),\n",
    "        \"format\": \"TSV\",\n",
    "        \"size\": \"2000\"\n",
    "        }\n",
    "\n",
    "    response = requests.post(\"https://api.gdc.cancer.gov/files\", json = params)\n",
    "\n",
    "    samples_info = pd.DataFrame([raw.strip().split(\"\\t\") for raw in response.content.decode(\"utf-8\").split(\"\\n\")][1:-1], columns=[name.split(\".\")[-1] for name in response.content.decode(\"utf-8\").split(\"\\n\")[0].strip().split(\"\\t\")]).drop(\"id\", axis=1) \n",
    "\n",
    "    return samples_info  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_raw_counts(dataset_name, samples_info, folder=\"\"):\n",
    "    filename2sampleID = dict(zip(samples_info.apply(lambda row: row[\"file_id\"]+\"/\"+row[\"file_name\"], axis=1), samples_info[\"submitter_id\"]))\n",
    "\n",
    "    raw_counts = None\n",
    "\n",
    "    with gzip.open(f\"{os.path.join(folder, dataset_name)}_raw_data.tar.gz\", \"rb\") as gz_file:\n",
    "        with tarfile.open(fileobj=gz_file, mode=\"r\") as tar:\n",
    "            for member in tqdm(tar.getmembers(), desc=f\"Extracting raw counts for {dataset_name}\"):\n",
    "                if member.isfile() and member.name.endswith(\".tsv\"):\n",
    "                    if raw_counts is None:\n",
    "                        raw_counts = pd.read_csv(tar.extractfile(member), sep=\"\\t\", header=1, skiprows=range(2,6), index_col=0).query(\"gene_type == 'protein_coding'\")[[\"gene_name\", \"unstranded\"]].rename(columns={\"unstranded\":filename2sampleID[member.name]})\n",
    "                    else:\n",
    "                        raw_counts = pd.concat([raw_counts, pd.read_csv(tar.extractfile(member), sep=\"\\t\", header=1, skiprows=range(2,6), index_col=0).query(\"gene_type == 'protein_coding'\")[[\"unstranded\"]].rename(columns={\"unstranded\":filename2sampleID[member.name]})], axis=1)\n",
    "\n",
    "    raw_counts.to_csv(f\"{os.path.join(folder, dataset_name)}_raw_counts.tsv.gz\", sep=\"\\t\", compression=\"gzip\")\n",
    "\n",
    "    return raw_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TCGA_datasets = pd.read_html(\"https://gdc.cancer.gov/resources-tcga-users/tcga-code-tables/tcga-study-abbreviations\")[1].query(\"`Study Name` != 'Controls' and `Study Name` != 'Miscellaneous' and `Study Name` != 'FFPE Pilot Phase II'\").reset_index(drop=True)\n",
    "# if not os.path.isdir(\"TCGA\"):\n",
    "#         os.makedirs(\"TCGA\")\n",
    "# TCGA_datasets.to_csv(\"TCGA/datasets.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_names = TCGA_datasets[\"Study Abbreviation\"]\n",
    "# only_disease = []\n",
    "# for dataset_name in dataset_names:\n",
    "#     if not os.path.isdir(\"TCGA\"):\n",
    "#         os.makedirs(\"TCGA\")\n",
    "#     print(f\"Dataset: {dataset_name}\")\n",
    "#     files_ids = get_files_ids(dataset_name)\n",
    "#     download_files(dataset_name, files_ids, folder=\"TCGA\")\n",
    "#     samples_info = download_samples_info(dataset_name, files_ids, folder=\"TCGA\")\n",
    "#     # save phenotypes info\n",
    "#     phenotypes = samples_info[[\"submitter_id\", \"sample_type\"]].set_index(\"submitter_id\").replace({\"Primary Tumor\":\"Diseased\", \"Metastatic\":\"Diseased\", \"Recurrent Tumor\":\"Diseased\", \"Additional - New Primary\":\"Diseased\", \"Additional Metastatic\":\"Diseased\", \"Solid Tissue Normal\":\"Healthy\"})\n",
    "#     phenotypes.to_csv(f\"TCGA/{dataset_name}_phenotypes.tsv\", sep=\"\\t\")\n",
    "#     if all(phenotypes[\"sample_type\"] == \"Diseased\"):\n",
    "#         only_disease.append(dataset_name)\n",
    "#     raw_counts = extract_raw_counts(dataset_name, samples_info, folder=\"TCGA\")\n",
    "#     os.remove(f\"TCGA/{dataset_name}_raw_data.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: GBM\n",
      "\tGetting files ids for GBM\n",
      "\tDownloading files for GBM\n",
      "\tDownloading samples info for GBM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting raw counts for GBM: 100%|██████████| 176/176 [01:45<00:00,  1.66it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"GBM\"\n",
    "only_disease = []\n",
    "\n",
    "print(f\"Dataset: {dataset_name}\")\n",
    "files_ids = get_files_ids(dataset_name)\n",
    "download_files(dataset_name, files_ids)\n",
    "samples_info = download_samples_info(dataset_name, files_ids)\n",
    "# save phenotypes info\n",
    "phenotypes = samples_info[[\"submitter_id\", \"sample_type\"]].set_index(\"submitter_id\").replace({\"Primary Tumor\":\"Diseased\", \"Metastatic\":\"Diseased\", \"Recurrent Tumor\":\"Diseased\", \"Additional - New Primary\":\"Diseased\", \"Additional Metastatic\":\"Diseased\", \"Solid Tissue Normal\":\"Healthy\"})\n",
    "phenotypes.to_csv(f\"{dataset_name}_phenotypes.tsv\", sep=\"\\t\")\n",
    "if all(phenotypes[\"sample_type\"] == \"Diseased\"):\n",
    "    only_disease.append(dataset_name)\n",
    "raw_counts = extract_raw_counts(dataset_name, samples_info)\n",
    "os.remove(f\"{dataset_name}_raw_data.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get HUGO Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hugo_genes.tsv\", \"wb\") as output_file:\n",
    "    response = requests.post(\"https://www.genenames.org/cgi-bin/download/custom?col=gd_app_sym&col=gd_app_name&status=Approved&hgnc_dbtag=on&order_by=gd_app_sym_sort&format=text&submit=submit\")\n",
    "    output_file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Ensembl Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<!DOCTYPE Query>\n",
    "<Query  virtualSchemaName = \"default\" formatter = \"TSV\" header = \"1\" uniqueRows = \"0\" count = \"\" datasetConfigVersion = \"0.6\" >\n",
    "\t\t\t\n",
    "\t<Dataset name = \"hsapiens_gene_ensembl\" interface = \"default\" >\n",
    "\t\t<Attribute name = \"ensembl_gene_id\" />\n",
    "\t\t<Attribute name = \"external_gene_name\" />\n",
    "\t</Dataset>\n",
    "</Query>\n",
    "\"\"\"\n",
    "url=\"http://www.ensembl.org/biomart/martservice?query=\"+query\n",
    "with open(\"ensemblId2geneName.tsv\", \"wb\") as output_file:\n",
    "\tresponse = requests.get(url)\n",
    "\toutput_file.write(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEGAJupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
